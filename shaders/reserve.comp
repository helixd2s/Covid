#version 460 core

//
// TODO! Planned to replace by FSR 2.0 or DLSS!!!

// 
#extension GL_GOOGLE_include_directive : require

//
#include "lib/native.glsl"
#include "lib/fresnel.glsl"
#include "lib/random.glsl"
#include "lib/rasterizer.glsl"
#include "lib/reprojection.glsl"

//
layout (local_size_x = 32, local_size_y = 4, local_size_z = 1) in;

//
vec4 readColor(in ivec2 pixelId, in uint type) {
  return imageLoad(imagesRgba16F[deferredBuf.images[0][1+type]], pixelId);
};

//
vec4 readPosition(in ivec2 pixelId, in uint type) {
  return imageLoad(imagesRgba32F[deferredBuf.images[0][5]], pixelId);
};

//
vec4 readNormal(in ivec2 pixelId, in uint type) {
  return imageLoad(imagesRgba16F[deferredBuf.images[0][4]], pixelId);
};

// TODO: use library or AI for fill such holes of rendering
// such as part of DLSS 2.x or FSR 2.0
vec4 readAndNeighborTex(in ivec2 pixelId, in uint tex) {
  vec4 center = vec4(0.f);
  if (pixelId.x < UR(deferredBuf.extent).x && pixelId.y < UR(deferredBuf.extent).y && pixelId.x >= 0 && pixelId.y >= 0) {
    uint linearId = pixelId.x + pixelId.y * UR(deferredBuf.extent).x;
    PixelSurfaceInfoRef info = getPixelSurface(linearId);
    center = info.tex[tex];
  };
  return center;
};

//
vec4 getDenoised(in ivec2 pixelId, in uint type) {
  vec4 sum = vec4(0.0);
  float c_phi = 1.0;
  float n_phi = 0.5;

  vec4 uval = readColor(pixelId, type);//readColorNeighbor(pixelId, type);
  vec4 cval = clampColW(uval);
  vec4 nval = readNormal(pixelId, type);

  float cum_w = 0.0;
  for(int i=0; i<25; i++)
  {
      ivec2 uv = pixelId+ivec2(offset[i]);

      vec4 ctmp = clampColW(readColor(uv, type));
      vec3 t = cval.xyz - ctmp.xyz; //t /= max(t.x, max(t.y, t.z));
      float dist2 = dot(t,t);
      float c_w = min(exp(-(dist2)/c_phi), 1.0);

      vec3 ntmp = readNormal(uv, type).xyz;
      t = nval.xyz - ntmp.xyz;
      dist2 = max(dot(t,t), 0.0);
      float n_w = min(exp(-(dist2)/n_phi), 1.0);

      float weight = c_w*n_w*ctmp.w*kernel[i];
      sum += ctmp*weight;
      cum_w += weight;
  };

  //
  return sum/max(cum_w, 0.0001f) * uval.w;
};

//
vec4 readColorComp(in ivec2 pixelId) {
  const vec4 resultRefl = clampColW(getDenoised(pixelId, 0));
  const vec4 resultTransp = clampColW(getDenoised(pixelId, 1));
  const vec4 resultColor = clampColW(getDenoised(pixelId, 2));
  const vec4 resultDiffuse = clampColW(readAndNeighborTex(pixelId, DIFFUSE_TEX));
  return (resultTransp * (1.f - resultDiffuse.a) + resultColor * resultDiffuse.a + resultRefl);
  //return clampColW(readDebugColor(pixelId, 2));
};




// TODO: use library or AI for fill such holes of rendering
// such as part of DLSS 2.x or FSR 2.0
void main() {
  const uvec2 gcoord = gl_GlobalInvocationID.xy;
  const vec2 tCoord = (vec2(gcoord) + 0.5f)/vec2(UR(deferredBuf.extent));
  const uint linearId = gcoord.x + UR(deferredBuf.extent).x * gcoord.y;
  const uint type = linearId / (UR(deferredBuf.extent).x * UR(deferredBuf.extent).y);
  const uint pixelId = linearId % (UR(deferredBuf.extent).x * UR(deferredBuf.extent).y);

  //
  const vec3 dstRayBegin = divW(vec4(vec3(tCoord, 0.f) * 2.f - 1.f, 1.f) * constants.perspectiveInverse) * constants.lookAtInverse[0];//fullTransform(instanceInfo, attrib.data[VERTEX_VERTICES], intersection.geometryId);
  const vec3 dstRayEnd = divW(vec4(vec3(tCoord, 1.f) * 2.f - 1.f, 1.f) * constants.perspectiveInverse) * constants.lookAtInverse[0];
  const vec3 dstRayDir = normalize(dstRayEnd.xyz - dstRayBegin.xyz);

  // 
  //const vec4 resultRefl = readColorWavelet(ivec2(gcoord), 0);
  //const vec4 resultTransp = readColorWavelet(ivec2(gcoord), 1);
  const vec4 resultColor = readColorComp(ivec2(gcoord));
  const vec4 resultEmission = readAndNeighborTex(ivec2(gcoord), EMISSION_TEX);
  const vec4 resultDiffuse = readAndNeighborTex(ivec2(gcoord), DIFFUSE_TEX);

  // 
  vec4 finalColor = vec4(clamp(
    resultColor + clampColW(resultEmission)
    //resultDiffuse
  , 0.f, 1.f).xyz, 1.f);

  //
  imageStore(imagesRgba32F[deferredBuf.images[0][0]], ivec2(gcoord), finalColor);
};
