#version 460 core

// 
#extension GL_GOOGLE_include_directive : require

//
#include "lib/native.glsl"
#include "lib/raytracing.glsl"
#include "lib/random.glsl"
#include "lib/sphere.glsl"
#include "lib/fresnel.glsl"
#include "lib/pass.glsl"

//
layout (local_size_x = 256, local_size_y = 1, local_size_z = 1) in;

//
vec3 proj_point_in_plane(in vec3 p, in vec3 v0, in vec3 n, out float d) {
  d = dot(n, p - v0);
  return p - (n * d);
};

//
vec3 find_reflection_incident_point(in vec3 p0, in vec3 p1, in vec3 v0, in vec3 n) {
  float d0 = 0;
  float d1 = 0;
  vec3 proj_p0 = proj_point_in_plane(p0, v0, n, d0);
  vec3 proj_p1 = proj_point_in_plane(p1, v0, n, d1);

  if(d1 < d0)
    return (proj_p0 - proj_p1) * d1/(d0+d1) + proj_p1;
  else
    return (proj_p1 - proj_p0) * d0/(d0+d1) + proj_p0;
};

// 
void main() {
  const uvec2 gcoord = gl_GlobalInvocationID.xy;
  const vec2 tCoord = vec2(gcoord)/vec2(extent);

  //
  const vec3 rayBegin = divW(vec4(vec3(tCoord, 0.f) * 2.f - 1.f, 1.f) * constants.perspectiveInverse) * constants.previousLookAtInverse;//fullTransform(instanceInfo, attrib.data[VERTEX_VERTICES], intersection.geometryId);
  const vec3 rayEnd = divW(vec4(vec3(tCoord, 1.f) * 2.f - 1.f, 1.f) * constants.perspectiveInverse) * constants.previousLookAtInverse;
  const vec3 rayDir = normalize(rayEnd.xyz - rayBegin.xyz);

  // TODO: convert into view space
  const uvec4 prevIndices = imageLoad(imagesRgba32UI[pingpong.images[2]], ivec2(gcoord));
  const uvec4 prevReflIndices = imageLoad(imagesRgba32UI[pingpong.images[10]], ivec2(gcoord));

  // 
  const vec4 prevPos = vec4(imageLoad(imagesRgba32F[pingpong.images[3]], ivec2(gcoord)).xyz, 1.f);
  const vec4 prevHitT = vec4(imageLoad(imagesRgba32F[pingpong.images[8]], ivec2(gcoord)).xyz, 1.f);
  const vec4 prevNormal = vec4(imageLoad(imagesRgba32F[pingpong.images[9]], ivec2(gcoord)).xyz, 0.f);
  const vec4 prevReflPos = vec4(prevPos.xyz + prevHitT.w * rayDir, 1.f);

  // 
  const vec4 currentPos = vec4(vec4(vec4(prevPos.xyz, 1.f) * inverse(getPrevInstanceTransform(instancedData.opaqueAddressInfo, prevIndices.x)), 1.f) * getInstanceTransform(instancedData.opaqueAddressInfo, prevIndices.x), 1.f);
  const vec4 currentReflPos = vec4(vec4(vec4(prevReflPos.xyz, 1.f) * inverse(getPrevInstanceTransform(instancedData.opaqueAddressInfo, prevReflIndices.x)), 1.f) * getInstanceTransform(instancedData.opaqueAddressInfo, prevReflIndices.x), 1.f);

  //
  const vec4 perspPos = vec4(vec4(currentPos.xyz, 1.f) * constants.lookAt, 1.f) * constants.perspective;
  const vec2 screenPos = (perspPos.xy/perspPos.w) * 0.5f + 0.5f;
  const ivec2 intScreenPos = ivec2(screenPos * vec2(extent));

  // TODO: correctly reproject previous reflection point
  const vec3 foundIntersection = find_reflection_incident_point(currentPos.xyz, prevReflPos.xyz, prevPos.xyz, normalize(prevNormal.xyz));
  const vec3 reprojIntersection = foundIntersection;//vec4(vec4(foundIntersection, 1.f) * inverse(getPrevInstanceTransform(instancedData.opaqueAddressInfo, prevReflIndices.x)), 1.f) * getInstanceTransform(instancedData.opaqueAddressInfo, prevReflIndices.x);

  // 
  const vec4 perspIntersection = vec4(vec4(reprojIntersection, 1.f) * constants.lookAt, 1.f) * constants.perspective;
  const vec2 whereReflect = (perspIntersection.xy / perspIntersection.w) * 0.5f + 0.5f;
  const ivec2 intWhereReflect = ivec2(whereReflect * vec2(extent));

  // 
  if (distance(texture(sampler2D(textures[framebufferAttachments[2]], samplers[0u]), screenPos, 0).xyz, currentPos.xyz) < 0.001f) {
    accumulateSplit(pingpong.images[1], intScreenPos, imageLoad(imagesRgba32UI[pingpong.images[0]], ivec2(gcoord))); // from previous diffuse

    // 
    if (distance(texture(sampler2D(textures[framebufferAttachments[2]], samplers[0u]), whereReflect, 0).xyz, reprojIntersection.xyz) < 0.001f) {
      accumulateSplit(pingpong.images[5], intWhereReflect, imageLoad(imagesRgba32UI[pingpong.images[4]], ivec2(gcoord)));
    };
  };

  
};
